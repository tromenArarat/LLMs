{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lógica proposicional clásica del profesor Pantano"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicio de las pruebas con inteligencia artificial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Cohere\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanciación del chat de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere.chat_models import ChatCohere\n",
    "\n",
    "llm = ChatCohere(model=\"command-r-plus\", language=\"es\", max_tokens=100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente en el estudio de la materia: {tema}. \"+\n",
    "            \"'Proposición' es una expresión que afirma algo, verdadero o falso, pero no ambas cosas a la vez. \"+\n",
    "            \"Por ejemplo: '6 es un número primo' es una proposición, pero 'x=2' no. \"+\n",
    "            \"Responde con la mayor síntesis posible \"+\n",
    "            \"a la pregunta de si el input es o no una proposición.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | llm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input y resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sí.\n"
     ]
    }
   ],
   "source": [
    "input = \"Jorge Luis Borges escribió el libro de cuentos 'Ficciones'\"\n",
    "\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sí, es una proposición.\n"
     ]
    }
   ],
   "source": [
    "input2 = \"¿Cómo?\"\n",
    "result2 = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input2 },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result2.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Términos categoremáticos (no lógicos) y sincategoremáticos (lógicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente en el estudio de la materia: {tema}. \"+\n",
    "            \"Los términos no lógicos, también llamados categoremáticos, son aquellos que tienen \"+\n",
    "            \"significado por sí mismos o que nombran objetos reales o imaginarios, como por ejemplo \"+\n",
    "            \"'simpático' o 'árbitro de fútbol'. \"+\n",
    "            \"Los términos lógicos, también llamados sincategoremáticos, no tienen significado por sí \"+\n",
    "            \"mismos y sólo lo adquieren acompañando, uniendo, estructurado, a los términos no lógicos. Así, por \"+\n",
    "            \"ejemplo, 'ningún', 'todos', 'es', 'no', etc. son términos lógicos. \"+\n",
    "            \"Responde con la mayor síntesis posible \"+\n",
    "            \"qué elementos del input son categoremáticos y cuáles sincategoremáticos.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = prompt | llm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Perro' y 'gato' son términos categoremáticos. 'Ningún' y 'es' son términos sincategoremáticos.\n"
     ]
    }
   ],
   "source": [
    "input = \"Ningún perro es gato\"\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificación de las proposiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Las proposiciones, a su vez, se pueden clasificar de distintas maneras. Un grupo de \"+\n",
    "            \"proposiciones particularmente importante, denominadas proposiciones categóricas, son las \"+\n",
    "            \"siguientes: \"+\n",
    "            \"Universal afirmativa: Todo S es P (de tipo A) \"+\n",
    "            \"Universal negativa: Ningún S es P (de tipo E) \"+\n",
    "            \"Particular afirmativa: Algún S es P (de tipo I) \"+\n",
    "            \"Particular negativa: Algún S es P (de tipo O) \"+\n",
    "            \"Responde con la mayor síntesis posible \"+\n",
    "            \"qué tipo de proposición es la provista en el input.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | llm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particular negativa (tipo O)\n"
     ]
    }
   ],
   "source": [
    "input = \"No todo lo que brilla es oro\"\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferencias por oposición"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contrarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Contrarias: dos proposiciones contrarias pueden ser simultáneamente falsas, pero no \"+\n",
    "            \"simultaneamente verdaderas. Si una es verdadera, la otra es falsa. Por ejemplo, si es verdadero que 'Todos los peces \"+\n",
    "            \"viven en el agua' es falsa la proposición 'Ningún pez vive en el agua', pero si una de las contrarias es \"+\n",
    "            \"falsa, nada se puede establecer acerca del valor de la otra. Habrá casos en que una es falsa y la otra \"+\n",
    "            \"también, y casos en que una será falsa y la otra verdadera.\"+\n",
    "            \"Responde con fundamento \"+\n",
    "            \"dada la expresión del input, ¿se puede determinar el valor de verdad de su expresión contraria?\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | llm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La expresión \"Todos los peces viven en el agua\" es una proposición universal afirmativa, que afirma que todos los peces, sin excepción, viven en el agua. Su expresión contraria sería una proposición universal negativa, que negaría que todos los peces viven en el agua.\n",
      "\n",
      "La expresión contraria de \"Todos los peces viven en el agua\" sería \"Ningún pez vive en el agua\". En este caso, sí se puede determinar el valor de verdad de su expresión contraria. Si la proposición original es verdadera, entonces su contraria es necesariamente falsa. Por lo tanto, si es verdadero que \"Todos los peces viven en el agua\", entonces es falso que \"Ningún pez vive en el agua\".\n",
      "\n",
      "En resumen, dada la expresión \"Todos los peces viven en el agua\", se puede determinar que su expresión contraria (\"Ningún pez vive en el agua\") es falsa si la proposición original es verdadera.\n"
     ]
    }
   ],
   "source": [
    "input = \"Todos los peces viven en el agua\"\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subcontrarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Subcontrarias: dos proposiciones subcontrarias pueden ser simultáneamente verdaderas, \"+\n",
    "            \"pero no falsas. Si una es falsa, la otra es verdadera necesariamente. \"+\n",
    "            \"Responde con fundamento \"+\n",
    "            \"dada la expresión del input, ¿se puede determinar el valor de verdad de su expresión subcontraria?\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | llm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sí, se puede determinar el valor de verdad de la expresión subcontraria. \n",
      "\n",
      "La expresión original, \"Algunos piratas visten saco y corbata\", indica que existe al menos un pirata que viste de esa manera. La expresión subcontraria sería \"Algunos piratas no visten saco y corbata\", y su valor de verdad puede determinarse a partir de la información dada.\n",
      "\n",
      "Si la expresión original es verdadera, entonces es razonable asumir que existen piratas que no visten saco y corbata. Por lo tanto, la expresión subcontraria \"Algunos piratas no visten saco y corbata\" también sería verdadera.\n",
      "\n",
      "Por otro lado, si la expresión original fuera falsa, y ningún pirata vistiera saco y corbata, entonces necesariamente todos los piratas no visten de esa manera. En este caso, la expresión subcontraria \"Algunos piratas no visten saco y corbata\" seguiría siendo verdadera.\n",
      "\n",
      "En resumen, la expresión subcontraria \"Algunos piratas no visten saco y corbata\" sería verdadera tanto si la expresión original es verdadera como si es falsa. Por lo tanto, se puede determinar que el valor de verdad de la expresión subcontraria es verdadero en este caso.\n"
     ]
    }
   ],
   "source": [
    "input = \"Algunos piratas visten saco y corbata\"\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Contradictorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Contradictorias: no pueden ser ni simultáneamente \"+\n",
    "            \"verdaderas ni simultáneamente falsas. Si una es falsa, la otra es necesariamente verdadera, \"+\n",
    "            \"y si una es verdadera, la otra es falsa necesariamente. \"+\n",
    "            \"Por ejemplo, de la falsedad de 'Todos los astronautas son \"+\n",
    "            \"norteamericanos” se infiere la verdad de 'Algunos astronautas no son norteamericanos'\"+\n",
    "            \"Dada la expresión del input, ¿se puede determinar el valor de verdad de su expresión contradictoria?\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | llm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La expresión contradictoria de la oración \"Todos los domingos los Benvenutti almuerzan pasta\" sería:\n",
      "\n",
      "\"Algunos domingos los Benvenutti no almuerzan pasta\".\n",
      "\n",
      "Esta expresión contradictoria es verdadera si la original es falsa, y falsa si la original es verdadera. Por ejemplo, si los Benvenutti a veces comen algo diferente a la pasta los domingos, entonces la primera oración es falsa y la expresión contradictoria es verdadera. Por otro lado, si los Benvenutti siempre comen pasta los domingos sin excepción, entonces la primera oración es verdadera y la expresión contradictoria es falsa.\n"
     ]
    }
   ],
   "source": [
    "input = \"Todos los domingos los Benvenutti almuerzan pasta\"\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subalternas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Subalternas: se llama subalternante a la proposición universal y su alternada a la particular \"\n",
    "            \"correspondiente. Si la subalternante es verdadera, la subalternada es verdadera, y si la subalternante \"+\n",
    "            \"es falsa, nada se puede inferir para la subalternada. Si la subalternada es falsa, la subalternante es \"+\n",
    "            \"falsa, y si la subalternada es verdadera, nada se puede inferir que la subalternante.\"+\n",
    "            \"Dada la expresión del input, ¿se puede determinar el valor de verdad de su expresión subalterna?\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | llm\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadera. Si la proposición universal \"Ninguna persona nace siendo mala\" es verdadera, entonces su proposición particular correspondiente, \"Algunas personas no nacen siendo malas\", también es verdadera.\n"
     ]
    }
   ],
   "source": [
    "input = \"Ninguna persona nace siendo mala\"\n",
    "result = with_message_history.invoke(\n",
    "    {\"tema\": \"Lógica Proposicional Clásica: \", \n",
    "     \"input\": input },\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

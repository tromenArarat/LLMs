{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciación del LLM\n",
    "- Prompt simple\n",
    "- Prompt en cadena con ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 0.3.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import Cohere`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import Cohere\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "llm = Cohere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Yes, there is a LM model named Mistral. Mistral is a wind of considerable velocity that occurs mainly in the Mediterranean region and southern France. It is a frigid, dry wind that originates from a warm core low pressure system. \\n\\nMistral winds are caused by a differential in atmospheric pressure between the mountain regions and the plains.  When the pressure is high over the mountain regions and low over the plains, Mistral winds will blow from the mountains towards the plains, clearing the air of dust and debris. \\n\\nIn the context of LM (Linguistic Model), Mistral refers to a highly efficient and powerful language model developed by the company Cohere. Known for its superior performance and capabilities, particularly in enterprise and business settings, the Mistral model offers advanced language understanding and intelligent assistance to users. It enables more complex and comprehensive conversational interactions and can handle nuanced requests and provide insightful responses. \\n\\nThe name Mistral was chosen to evoke the wind's characteristics associated with clarity, freshness, and a powerful force driving change and progress. \\n\\nIf you want to know more about the Mistral wind or LM model, there is information available on both topics that can be adapted to your specific needs or interests. \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt simple\n",
    "llm.invoke(\"Existe un modelo de llm que se llama Mistral?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" No, pawns cannot capture en passant in columns A or B. En passant is a special rule that applies when a pawn is moved two squares on its first move, and passes by an opponent's pawn which then can capture it. This move is only available on the player's second move and applies only to pawns that have not yet been moved. Also, the capturing is done by the opponent's pawn that is adjacent to the pawn in the row behind it. Columns A and B are behind the full set of columns, and thus en passant is not available to pawns in those columns. \\n\\nThe idea that a rule could apply in some instances and not others shouldn't be controversial in your mind, right? If you think that a rule should apply across all contexts, then you might believe that gravity should not exist in some places, or that mass should not have a conservation principle. If you find that your thinking has applied to this new context, then you might wonder why these chess pieces can't eat each other en passant. \\n\\nLet me know if I can offer you more explanations of en passant or other chess rules so you can gain a better understanding of this fascinating rule! \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cadena\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant to remind chess rules\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"input\":\"can pawn in column a eat enpassant pawn from columns b?\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_cohere.chat_models import ChatCohere\n",
    "\n",
    "model = ChatCohere()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente especializado en {habilidad}. Puedes responder preguntas sobre {habilidad}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el ajedrez, una \"ganancia de tempo\" (también conocida como \"ganancia de tiempo\") es una jugada que permite a un jugador lograr una posición ventajosa al obligar al oponente a gastar uno o más movimientos en defender o proteger una pieza amenazada. Es una táctica importante en el ajedrez, ya que permite a un jugador ganar una ventaja temporal en el desarrollo de sus piezas o en la iniciativa del juego.\n",
      "\n",
      "La idea clave detrás de la ganancia de tempo es que un jugador puede sacrificar temporalmente una pieza (normalmente un peón) para desviar las piezas del oponente o forzarlo a mover una pieza a una posición menos favorable. Esto le da al jugador que gana tempo una oportunidad de desarrollar sus propias piezas de manera más eficiente, ganar espacio en el tablero o lanzar un ataque.\n",
      "\n",
      "Por ejemplo, una ganancia de tempo común es el \"ataque al peón de la dama\", donde un jugador mueve su caballo a la casilla controlada por el peón de la dama del oponente (f3 para las blancas o f6 para las negras). El oponente debe entonces mover su peón de la dama para defenderlo, lo que a menudo retrasa su desarrollo o debilita su posición.\n",
      "\n",
      "En resumen, la ganancia de tempo es una táctica valiosa en el ajedrez que implica sacrificar temporalmente material para obtener una ventaja posicional o de desarrollo. Es una herramienta importante para cualquier jugador de ajedrez que busca ganar la iniciativa y controlar el flujo del juego.\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"habilidad\": \"ajedrez\", \"input\": \"qué es una ganancia de tempo?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La ganancia de tempo en el ajedrez se refiere a una táctica en la que un jugador logra una ventaja temporal en el desarrollo de sus piezas o en la iniciativa del juego. Aquí hay un ejemplo para ilustrar cómo funciona:\n",
      "\n",
      "Supongamos que las blancas juegan 1.e4 (movimiento del peón de rey dos casillas hacia adelante) y las negras responden con 1...e5 (simétrico).\n",
      "\n",
      "2. Cf3\n",
      "\n",
      "Aquí, las blancas desarrollan su caballo a una casilla agresiva y activa, atacando el peón de las negras en e5.\n",
      "\n",
      "2... Cc6\n",
      "\n",
      "Las negras responden de manera similar, desarrollando su caballo y atacando el peón de las blancas en e4.\n",
      "\n",
      "3. Ac4\n",
      "\n",
      "En este momento, las blancas pueden intentar una ganancia de tempo con el movimiento 3. Ac4. Este movimiento parece un poco inusual, ya que el alfil normalmente se desarrolla en diagonal hacia su posición más activa en el centro del tablero. Sin embargo, en este caso, el alfil se mueve a c4 con una idea específica.\n",
      "\n",
      "La idea detrás de 3. Ac4 es atacar el peón de las negras en f7, que está solo defendido por el rey negro. Este ataque obliga a las negras a defender el peón de alguna manera, ya sea moviendo el rey o reforzando la defensa del peón con otra pieza.\n",
      "\n",
      "Digamos que las negras eligen la opción más común y responden con 3... Cf6, moviendo su caballo para defender el peón atacado.\n",
      "\n",
      "Ahora, las blancas han ganado un tempo. ¿Por qué? Porque las negras se vieron obligadas a gastar un movimiento defendiendo su peón en f7, mientras que las blancas pudieron desarrollar su alfil a una casilla activa, influyendo en el centro del tablero.\n",
      "\n",
      "Después de 4... Cf6, las blancas pueden continuar su desarrollo de piezas de manera eficiente, por ejemplo, moviendo su otro caballo a 5. Cc3, atacando el peón en e5 y preparando el enroque.\n",
      "\n",
      "En resumen, la secuencia de movimientos podría verse así:\n",
      "\n",
      "1. e4 e5 2. Cf3 Cc6 3. Ac4 Cf6 4. Cc3\n",
      "\n",
      "En este ejemplo, las blancas ganaron un tempo al obligar a las negras a defender su peón en f7, lo que les permitió desarrollar su alfil y su caballo a posiciones activas y preparar el enroque. Esta es la esencia de la ganancia de tempo en el ajedrez: lograr una ventaja temporal en el desarrollo o la iniciativa del juego.\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"habilidad\": \"ajedrez\", \"input\": \"cómo?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento, no entendí tu pregunta. ¿A qué te refieres con \"cómo\"? Si tienes alguna duda o pregunta relacionada con el ajedrez, estaré encantado de ayudarte.\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"habilidad\": \"ajedrez\", \"input\": \"cómo?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc124\"}},\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herramientas de langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query',\n",
       "  'description': 'query to look up on wikipedia',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Buenos Aires Club Argentino Chess Championship\\nSummary: Club Argentino de Ajedrez was founded '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tool.run({\"query\": \"langchain\"})\n",
    "\n",
    "tool.run(\"ajedrez argentino\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.clarin.com/deportes/argentina-vs-ucrania-juegos-olimpicos-paris-2024-resultado-necesita-seleccion-clasificarse-cuartos-final_0_jsMGseBevb.html',\n",
       "  'content': 'Argentina vs Ucrania, por los Juegos Olímpicos París 2024: qué resultado necesita la Selección para clasificarse a cuartos de final ... El nuevo rol de Julián Álvarez en la Sub-23, Gallardo ...'},\n",
       " {'url': 'https://www.espn.com.mx/olimpicos/nota/_/id/13968448/argentina-gano-ucrania-juegos-olimpicos-cuartos-de-final-rival-francia',\n",
       "  'content': 'Por qué es importante este duelo de los Juegos Olímpicos. Argentina y Ucrania se juegan su futuro en el torneo olímpico de fútbol masculino. ... En Argentina se destaca Julián Álvarez ...'},\n",
       " {'url': 'https://www.espn.com.ar/olimpicos/nota/_/id/13968448/argentina-gano-ucrania-juegos-olimpicos-cuartos-de-final-rival-francia',\n",
       "  'content': 'Argentina y Ucrania, en la tercera y última fecha del grupo B del torneo de los Juegos Olímpicos de París 2024, disputaron un buen primer tiempo de ida y vuelta, pero se fueron igualados en cero al entretiempo. Thiago Almada se despachó con un golazo para abrir el marcador frente a Ucrania en los Juegos Olímpicos. Getty Images'},\n",
       " {'url': 'https://espndeportes.espn.com/olimpicos/nota/_/id/13968448/cuando-juegan-argentina-vs-ucrania-por-los-juegos-olimpicos-equipo-fecha-hora-y-tv-en-vivo',\n",
       "  'content': 'Argentina enfrenta a Ucrania, en la tercera y última fecha del grupo B del torneo de los Juegos Olímpicos de París 2024.El partido se juega el martes 30 de julio, a las 12 hora argentina, en el ...'},\n",
       " {'url': 'https://www.ole.com.ar/juegos-olimpicos/video-goles-resumen-seleccion-argentina-ucrania-juegos-olimpicos_0_04PReK4mXh.html',\n",
       "  'content': 'Argentina superó a Ucrania y jugará contra Francia en los cuartos de los Juegos Olímpicos 2024 Mirá también Argentina vs. Francia, por los Juegos Olímpicos: día, a qué hora juegan y cómo ver'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"¿Cómo salió Argentina-Ucrania en los juegos olímpicos?, ¿qué tal el desempeño de Julián Álvarez?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El hub es los prompts de los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentExecutor\n\u001b[0;32m      7\u001b[0m agent_executor \u001b[39m=\u001b[39m AgentExecutor(agent\u001b[39m=\u001b[39magent, tools\u001b[39m=\u001b[39mtools, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m agent_executor\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mhola!\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    157\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1612\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1612\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m   1613\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1614\u001b[0m         color_mapping,\n\u001b[0;32m   1615\u001b[0m         inputs,\n\u001b[0;32m   1616\u001b[0m         intermediate_steps,\n\u001b[0;32m   1617\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m   1618\u001b[0m     )\n\u001b[0;32m   1619\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1620\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m   1621\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m   1622\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1318\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_next_step\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     name_to_tool_map: Dict[\u001b[39mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1316\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m   1317\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1318\u001b[0m         [\n\u001b[0;32m   1319\u001b[0m             a\n\u001b[0;32m   1320\u001b[0m             \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter_next_step(\n\u001b[0;32m   1321\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1322\u001b[0m                 color_mapping,\n\u001b[0;32m   1323\u001b[0m                 inputs,\n\u001b[0;32m   1324\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1325\u001b[0m                 run_manager,\n\u001b[0;32m   1326\u001b[0m             )\n\u001b[0;32m   1327\u001b[0m         ]\n\u001b[0;32m   1328\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1318\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_next_step\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     name_to_tool_map: Dict[\u001b[39mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1316\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m   1317\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1318\u001b[0m         [\n\u001b[0;32m   1319\u001b[0m             a\n\u001b[0;32m   1320\u001b[0m             \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter_next_step(\n\u001b[0;32m   1321\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1322\u001b[0m                 color_mapping,\n\u001b[0;32m   1323\u001b[0m                 inputs,\n\u001b[0;32m   1324\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1325\u001b[0m                 run_manager,\n\u001b[0;32m   1326\u001b[0m             )\n\u001b[0;32m   1327\u001b[0m         ]\n\u001b[0;32m   1328\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:1346\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1343\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1345\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1346\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[0;32m   1347\u001b[0m         intermediate_steps,\n\u001b[0;32m   1348\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1349\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[0;32m   1350\u001b[0m     )\n\u001b[0;32m   1351\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1352\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain\\agents\\agent.py:580\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m final_output: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_runnable:\n\u001b[0;32m    574\u001b[0m     \u001b[39m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[39m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[39m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     \u001b[39m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunnable\u001b[39m.\u001b[39;49mstream(inputs, config\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m: callbacks}):\n\u001b[0;32m    581\u001b[0m         \u001b[39mif\u001b[39;49;00m final_output \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[0;32m    582\u001b[0m             final_output \u001b[39m=\u001b[39;49m chunk\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3253\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstream\u001b[39m(\n\u001b[0;32m   3248\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   3249\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[0;32m   3250\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3251\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3252\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3253\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(\u001b[39miter\u001b[39m([\u001b[39minput\u001b[39m]), config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3240\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\n\u001b[0;32m   3235\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   3236\u001b[0m     \u001b[39minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   3237\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3238\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3239\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3240\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3241\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[0;32m   3242\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform,\n\u001b[0;32m   3243\u001b[0m         patch_config(config, run_name\u001b[39m=\u001b[39m(config \u001b[39mor\u001b[39;00m {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[0;32m   3244\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3245\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2053\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2051\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2052\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 2053\u001b[0m         chunk: Output \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(\u001b[39mnext\u001b[39m, iterator)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m   2054\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n\u001b[0;32m   2055\u001b[0m         \u001b[39mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3202\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3199\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3200\u001b[0m         final_pipeline \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3202\u001b[0m \u001b[39mfor\u001b[39;49;00m output \u001b[39min\u001b[39;49;00m final_pipeline:\n\u001b[0;32m   3203\u001b[0m     \u001b[39myield\u001b[39;49;00m output\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1271\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1268\u001b[0m final: Input\n\u001b[0;32m   1269\u001b[0m got_first_val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1271\u001b[0m \u001b[39mfor\u001b[39;49;00m ichunk \u001b[39min\u001b[39;49;00m \u001b[39minput\u001b[39;49m:\n\u001b[0;32m   1272\u001b[0m     \u001b[39m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[0;32m   1273\u001b[0m     \u001b[39m# then call stream.\u001b[39;49;00m\n\u001b[0;32m   1274\u001b[0m     \u001b[39m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[0;32m   1275\u001b[0m     \u001b[39m# the `+` operator.\u001b[39;49;00m\n\u001b[0;32m   1276\u001b[0m     \u001b[39m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[0;32m   1277\u001b[0m     \u001b[39m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[0;32m   1278\u001b[0m     \u001b[39m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m got_first_val:\n\u001b[0;32m   1280\u001b[0m         final \u001b[39m=\u001b[39;49m ichunk\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5267\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\n\u001b[0;32m   5262\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5263\u001b[0m     \u001b[39minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   5264\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   5265\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m   5266\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 5267\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbound\u001b[39m.\u001b[39mtransform(\n\u001b[0;32m   5268\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[0;32m   5269\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5270\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs},\n\u001b[0;32m   5271\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1289\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1286\u001b[0m             final \u001b[39m=\u001b[39m ichunk\n\u001b[0;32m   1288\u001b[0m \u001b[39mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1289\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream(final, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:373\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    367\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(\n\u001b[0;32m    368\u001b[0m         e,\n\u001b[0;32m    369\u001b[0m         response\u001b[39m=\u001b[39mLLMResult(\n\u001b[0;32m    370\u001b[0m             generations\u001b[39m=\u001b[39m[[generation]] \u001b[39mif\u001b[39;00m generation \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    371\u001b[0m         ),\n\u001b[0;32m    372\u001b[0m     )\n\u001b[1;32m--> 373\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_end(LLMResult(generations\u001b[39m=\u001b[39m[[generation]]))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:353\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrate_limiter\u001b[39m.\u001b[39macquire(blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream(messages, stop\u001b[39m=\u001b[39;49mstop, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs):\n\u001b[0;32m    354\u001b[0m         \u001b[39mif\u001b[39;49;00m chunk\u001b[39m.\u001b[39;49mmessage\u001b[39m.\u001b[39;49mid \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[0;32m    355\u001b[0m             chunk\u001b[39m.\u001b[39;49mmessage\u001b[39m.\u001b[39;49mid \u001b[39m=\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrun-\u001b[39;49m\u001b[39m{\u001b[39;49;00mrun_manager\u001b[39m.\u001b[39;49mrun_id\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:521\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    519\u001b[0m     base_generation_info \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mdict\u001b[39m(raw_response\u001b[39m.\u001b[39mheaders)}\n\u001b[0;32m    520\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpayload)\n\u001b[0;32m    522\u001b[0m     base_generation_info \u001b[39m=\u001b[39m {}\n\u001b[0;32m    523\u001b[0m \u001b[39mwith\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    613\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    614\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    644\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    645\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 646\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    647\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    648\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    649\u001b[0m             {\n\u001b[0;32m    650\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    651\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    652\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    653\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    654\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    655\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    656\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[0;32m    657\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    658\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    659\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparallel_tool_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: parallel_tool_calls,\n\u001b[0;32m    660\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    661\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    662\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    663\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mservice_tier\u001b[39;49m\u001b[39m\"\u001b[39;49m: service_tier,\n\u001b[0;32m    664\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    665\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    666\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[0;32m    667\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    668\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    669\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    670\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[0;32m    671\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    672\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    673\u001b[0m             },\n\u001b[0;32m    674\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    675\u001b[0m         ),\n\u001b[0;32m    676\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    677\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    678\u001b[0m         ),\n\u001b[0;32m    679\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    680\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    681\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    682\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    943\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    944\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    945\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    946\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    947\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    948\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m   1030\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m-> 1031\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m   1032\u001b[0m         input_options,\n\u001b[0;32m   1033\u001b[0m         cast_to,\n\u001b[0;32m   1034\u001b[0m         retries,\n\u001b[0;32m   1035\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m   1036\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m   1037\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1040\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1079\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m   1080\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m   1081\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m   1082\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m   1083\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m   1084\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m   1085\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1031\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m   1030\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m-> 1031\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m   1032\u001b[0m         input_options,\n\u001b[0;32m   1033\u001b[0m         cast_to,\n\u001b[0;32m   1034\u001b[0m         retries,\n\u001b[0;32m   1035\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m   1036\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m   1037\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1040\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1075\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1079\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m   1080\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m   1081\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m   1082\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m   1083\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m   1084\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m   1085\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m   1045\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[0;32m   1049\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m   1050\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m   1054\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"hola!\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
